{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CV - Ruslan Borisenco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "from textwrap import dedent\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comma(x):\n",
    "    return ', '.join(x)\n",
    "\n",
    "def newline(x):\n",
    "    return '\\n'.join(x)\n",
    "\n",
    "def normalize(x):\n",
    "    return dedent(x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_template = Template(\"\"\"\n",
    "# Ruslan Borisenco\n",
    "\n",
    "email: ruslanborysenko@gmail.com <br>\n",
    "tel: 730 837 748 <br>\n",
    "linkedin: https://www.linkedin.com/in/ruslan-borisenco-60a56319b/ <br>\n",
    "github: https://github.com/ruslanborysenko-lab\n",
    "\n",
    "${intro}\n",
    "\n",
    "## Projects\n",
    "\n",
    "${projects}\n",
    "\n",
    "## Technical Skills\n",
    "\n",
    "- **Programming Languages**: ${skills_languages}\n",
    "- **Libraries and Tools**: ${skills_tools}\n",
    "- **Databases**: ${skills_databases}\n",
    "- **Other**: ${skills_other}\n",
    "\n",
    "## Portfolio\n",
    "\n",
    "[Visit my portfolio here](${portfolio_url})\n",
    "\n",
    "## Education\n",
    "\n",
    "${education}\n",
    "\n",
    "## Languages\n",
    "\n",
    "${languages}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_template = Template(\"\"\"\n",
    "### $name\n",
    "\n",
    "$description\n",
    "\n",
    "- **Skills**: $skills\n",
    "- **Results**: $result\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_school_template = Template(\"\"\"\n",
    "- **${degree}** – ${school} – ${years}\n",
    "\"\"\")\n",
    "\n",
    "education_course_template = Template(\"\"\"\n",
    "- **${course}** - ${provider} - ${date}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_template = Template(\"\"\"\n",
    "- **${language}**: ${level}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Ruslan Borisenco\n",
       "\n",
       "email: ruslanborysenko@gmail.com <br>\n",
       "tel: 730 837 748 <br>\n",
       "linkedin: https://www.linkedin.com/in/ruslan-borisenco-60a56319b/ <br>\n",
       "github: https://github.com/ruslanborysenko-lab\n",
       "\n",
       "Junior Data Scientist specializing in end-to-end ML pipeline development, computer vision, NLP, and cloud-based solutions. \n",
       "Experienced in building production-ready AI systems from data exploration through deployment, with focus on MLOps, \n",
       "LLM integration, and business intelligence dashboards.\n",
       "\n",
       "Develop and deploy machine learning models for diverse applications including OCR invoice processing, conversational AI chatbots, \n",
       "clustering algorithms for recommendation systems, and predictive analytics. Design interactive data visualization dashboards \n",
       "for survey analytics and business metrics. Implement semantic search systems with vector embeddings and optimize warehouse \n",
       "operations using data-driven approaches.\n",
       "\n",
       "Proficient in Python ecosystem (pandas, scikit-learn), cloud platforms. Strong foundation in exploratory data analysis, statistical modeling, \n",
       "and SQL database management. Demonstrated ability to translate business requirements into technical solutions with measurable impact.\n",
       "\n",
       "## Projects\n",
       "\n",
       "\n",
       "### Half Marathon Time Prediction - ML & NLP\n",
       "\n",
       "ML-powered web app predicting half marathon finish times from 5km results using PyCaret regression models (R²>0.85) trained on 8,000+ runner dataset. Features GPT-4o-mini NLP for natural language input parsing, cloud model storage on Digital Ocean Spaces, Langfuse LLM observability, and comparative analytics with 14 age/gender categories.\n",
       "\n",
       "- **Skills**: PyCaret, OpenAI GPT-4o-mini, Langfuse, Digital Ocean Spaces, boto3, Streamlit, pandas, matplotlib\n",
       "- **Results**: R²>0.85 model on 8,000+ samples, cloud deployment with LLM monitoring, natural language NLP parsing\n",
       "\n",
       "\n",
       "### TransStream - Warehouse Workforce Optimization\n",
       "\n",
       "Enterprise-grade workforce optimization system combining GPT-4o AI with business intelligence analytics. Analyzes 1,500m² warehouse operations (May-Sept), optimizes 5 employee roles using formula-based calculations, forecasts Oct-Dec staffing with linear regression. Features 10+ interactive dashboards, executive KPIs, and real-time optimization. Largest project (1,369 lines of code).\n",
       "\n",
       "- **Skills**: OpenAI GPT-4o, Prompt Engineering, Linear Regression, Streamlit, Plotly, pandas, Business Intelligence\n",
       "- **Results**: 60% Loader reduction (10→4), executive dashboard with 4 KPIs, 3-month forecast, 10+ visualizations\n",
       "\n",
       "\n",
       "### ML Friend Finder - Clustering Application\n",
       "\n",
       "Machine learning application using K-Means clustering to match users with similar interests. Built with PyCaret for automated ML pipeline and Streamlit for web interface. Trained on 229 survey respondents, the model segments users into 8 groups. Features real-time prediction, interactive visualizations, and Polish localization.\n",
       "\n",
       "- **Skills**: K-Means Clustering, PyCaret, Unsupervised Learning, Streamlit, Plotly, Feature Engineering\n",
       "- **Results**: 8 user segments, 5→21 feature transformation, Silhouette Score 0.195, <1s prediction with caching\n",
       "\n",
       "\n",
       "### AI Voice Notes - Semantic Search Application\n",
       "\n",
       "Advanced voice notes app with AI-powered transcription and semantic search. Built with OpenAI Whisper for speech-to-text, text-embedding-3-large for 3072-dim vectors, and Qdrant for similarity search. Features browser audio recording, MD5 caching, and cloud deployment. Find notes by meaning, not just keywords.\n",
       "\n",
       "- **Skills**: OpenAI Whisper, Vector Embeddings, Qdrant, Semantic Search, Streamlit, Audio Processing\n",
       "- **Results**: 3072-dim vectors, <1s semantic search, MD5 caching for cost optimization, cloud deployment\n",
       "\n",
       "\n",
       "### Interactive Survey Data Analysis Dashboard\n",
       "\n",
       "Comprehensive data visualization web app analyzing 140 student profiles across 11 variables. Built with Streamlit and Plotly, featuring interactive charts, correlation analysis, and automated insights. Implemented smart category ordering, missing data handling, and multi-stage analytics pipeline for educational program optimization.\n",
       "\n",
       "- **Skills**: Streamlit, Plotly, pandas, Statistical Analysis, Data Visualization, Correlation Analysis\n",
       "- **Results**: 11 analytical modules, 3-stage pipeline, 1,030 lines of code, regex age interval parser, comparative analytics\n",
       "\n",
       "\n",
       "### AI Chatbot Web Application\n",
       "\n",
       "Production-ready web chatbot built with Streamlit and OpenAI GPT-4o/GPT-5. Features multi-conversation management, customizable AI personalities, persistent JSON-based storage, and token usage tracking. Implemented session state management and 20-message memory window for cost optimization.\n",
       "\n",
       "- **Skills**: Streamlit, OpenAI GPT-4o, Session State Management, JSON, API Integration\n",
       "- **Results**: Unlimited conversations, 20-message memory window (~60% token reduction), token usage tracking\n",
       "\n",
       "\n",
       "### AI-Powered Invoice Data Extraction System\n",
       "\n",
       "Automated data processing pipeline using OpenAI GPT-4o Vision API to extract structured information from invoice images. Integrated multi-source data (SQLite, CSV, images) into unified dataset. Achieved 100% automation of manual invoice processing using LLM with Pydantic validation.\n",
       "\n",
       "- **Skills**: OpenAI GPT-4o Vision, Pydantic, pandas, SQLite, ETL, Data Integration\n",
       "- **Results**: 100% automation, processed 10 invoices with 16+ line items, integrated 3 data sources, type-safe validation\n",
       "\n",
       "\n",
       "### Titanic Disaster Survival Analysis\n",
       "\n",
       "Comprehensive exploratory data analysis of 1,310 Titanic passengers examining survival patterns by class, gender, age, and family size. Analyzed correlations between socioeconomic status and survival rates, identified rescue priorities (73% female survival vs 20% male), and explored lifeboat allocation patterns across passenger classes.\n",
       "\n",
       "- **Skills**: pandas, matplotlib, Statistical Analysis, Missing Data Analysis, Correlation Analysis\n",
       "- **Results**: Identified 73% vs 20% survival disparity, handled 77% missing cabin data, analyzed 27 lifeboats\n",
       "\n",
       "\n",
       "### Iris Species Classification - EDA\n",
       "\n",
       "Comprehensive exploratory data analysis of the classic Iris flower dataset covering three species (setosa, versicolor, virginica). Performed statistical analysis on 150 samples with 4 morphological features, including correlation analysis, distribution studies, and species differentiation using pandas visualization.\n",
       "\n",
       "- **Skills**: pandas, NumPy, matplotlib, Descriptive Statistics, Data Visualization\n",
       "- **Results**: Identified petal length as strongest discriminator, 0.75 correlation for setosa, zero missing values\n",
       "\n",
       "\n",
       "## Technical Skills\n",
       "\n",
       "- **Programming Languages**: Python, SQL\n",
       "- **Libraries and Tools**: pandas, scikit-learn, PyCaret, OpenAI API, Streamlit, Plotly, matplotlib, seaborn, Git, Jupyter Notebook, Docker\n",
       "- **Databases**: SQLite, Qdrant\n",
       "- **Other**: Google Cloud, Digital Ocean, Langfuse, Prompt Engineering, Vector Databases, REST APIs\n",
       "\n",
       "## Portfolio\n",
       "\n",
       "[Visit my portfolio here](https://github.com/ruslanborysenko-lab)\n",
       "\n",
       "## Education\n",
       "\n",
       "\n",
       "- **From Zero to AI** - Gotoit - 2025\n",
       "\n",
       "\n",
       "- **Bachelor of Engineering - BE, Engineer-constructor** – Dniepropetrovsk State University, Ukraine, Faculty of physics and technology – 1993-1998\n",
       "\n",
       "\n",
       "## Languages\n",
       "\n",
       "\n",
       "- **English**: B2\n",
       "\n",
       "\n",
       "- **Polish**: B2\n",
       "\n",
       "\n",
       "- **Ukrainian**: Native\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_md = cv_template.substitute(\n",
    "    intro=normalize(\"\"\"\n",
    "Junior Data Scientist specializing in end-to-end ML pipeline development, computer vision, NLP, and cloud-based solutions. \n",
    "Experienced in building production-ready AI systems from data exploration through deployment, with focus on MLOps, \n",
    "LLM integration, and business intelligence dashboards.\n",
    "\n",
    "Develop and deploy machine learning models for diverse applications including OCR invoice processing, conversational AI chatbots, \n",
    "clustering algorithms for recommendation systems, and predictive analytics. Design interactive data visualization dashboards \n",
    "for survey analytics and business metrics. Implement semantic search systems with vector embeddings and optimize warehouse \n",
    "operations using data-driven approaches.\n",
    "\n",
    "Proficient in Python ecosystem (pandas, scikit-learn), cloud platforms. Strong foundation in exploratory data analysis, statistical modeling, \n",
    "and SQL database management. Demonstrated ability to translate business requirements into technical solutions with measurable impact.\n",
    "    \"\"\"),\n",
    "    projects=newline([\n",
    "        project_template.substitute({\n",
    "            \"name\": \"Half Marathon Time Prediction - ML & NLP\",\n",
    "            \"description\": \"ML-powered web app predicting half marathon finish times from 5km results using PyCaret regression models (R²>0.85) trained on 8,000+ runner dataset. Features GPT-4o-mini NLP for natural language input parsing, cloud model storage on Digital Ocean Spaces, Langfuse LLM observability, and comparative analytics with 14 age/gender categories.\",\n",
    "            \"skills\": comma([\"PyCaret\", \"OpenAI GPT-4o-mini\", \"Langfuse\", \"Digital Ocean Spaces\", \"boto3\", \"Streamlit\", \"pandas\", \"matplotlib\"]),\n",
    "            \"result\": \"R²>0.85 model on 8,000+ samples, cloud deployment with LLM monitoring, natural language NLP parsing\"\n",
    "        }),\n",
    "        project_template.substitute({\n",
    "            \"name\": \"TransStream - Warehouse Workforce Optimization\",\n",
    "            \"description\": \"Enterprise-grade workforce optimization system combining GPT-4o AI with business intelligence analytics. Analyzes 1,500m² warehouse operations (May-Sept), optimizes 5 employee roles using formula-based calculations, forecasts Oct-Dec staffing with linear regression. Features 10+ interactive dashboards, executive KPIs, and real-time optimization. Largest project (1,369 lines of code).\",\n",
    "            \"skills\": comma([\"OpenAI GPT-4o\", \"Prompt Engineering\", \"Linear Regression\", \"Streamlit\", \"Plotly\", \"pandas\", \"Business Intelligence\"]),\n",
    "            \"result\": \"60% Loader reduction (10→4), executive dashboard with 4 KPIs, 3-month forecast, 10+ visualizations\"\n",
    "        }),\n",
    "        project_template.substitute({\n",
    "            \"name\": \"ML Friend Finder - Clustering Application\",\n",
    "            \"description\": \"Machine learning application using K-Means clustering to match users with similar interests. Built with PyCaret for automated ML pipeline and Streamlit for web interface. Trained on 229 survey respondents, the model segments users into 8 groups. Features real-time prediction, interactive visualizations, and Polish localization.\",\n",
    "            \"skills\": comma([\"K-Means Clustering\", \"PyCaret\", \"Unsupervised Learning\", \"Streamlit\", \"Plotly\", \"Feature Engineering\"]),\n",
    "            \"result\": \"8 user segments, 5→21 feature transformation, Silhouette Score 0.195, <1s prediction with caching\"\n",
    "        }),\n",
    "        project_template.substitute({\n",
    "            \"name\": \"AI Voice Notes - Semantic Search Application\",\n",
    "            \"description\": \"Advanced voice notes app with AI-powered transcription and semantic search. Built with OpenAI Whisper for speech-to-text, text-embedding-3-large for 3072-dim vectors, and Qdrant for similarity search. Features browser audio recording, MD5 caching, and cloud deployment. Find notes by meaning, not just keywords.\",\n",
    "            \"skills\": comma([\"OpenAI Whisper\", \"Vector Embeddings\", \"Qdrant\", \"Semantic Search\", \"Streamlit\", \"Audio Processing\"]),\n",
    "            \"result\": \"3072-dim vectors, <1s semantic search, MD5 caching for cost optimization, cloud deployment\"\n",
    "        }),\n",
    "        project_template.substitute({\n",
    "            \"name\": \"Interactive Survey Data Analysis Dashboard\",\n",
    "            \"description\": \"Comprehensive data visualization web app analyzing 140 student profiles across 11 variables. Built with Streamlit and Plotly, featuring interactive charts, correlation analysis, and automated insights. Implemented smart category ordering, missing data handling, and multi-stage analytics pipeline for educational program optimization.\",\n",
    "            \"skills\": comma([\"Streamlit\", \"Plotly\", \"pandas\", \"Statistical Analysis\", \"Data Visualization\", \"Correlation Analysis\"]),\n",
    "            \"result\": \"11 analytical modules, 3-stage pipeline, 1,030 lines of code, regex age interval parser, comparative analytics\"\n",
    "        }),\n",
    "        project_template.substitute({\n",
    "            \"name\": \"AI Chatbot Web Application\",\n",
    "            \"description\": \"Production-ready web chatbot built with Streamlit and OpenAI GPT-4o/GPT-5. Features multi-conversation management, customizable AI personalities, persistent JSON-based storage, and token usage tracking. Implemented session state management and 20-message memory window for cost optimization.\",\n",
    "            \"skills\": comma([\"Streamlit\", \"OpenAI GPT-4o\", \"Session State Management\", \"JSON\", \"API Integration\"]),\n",
    "            \"result\": \"Unlimited conversations, 20-message memory window (~60% token reduction), token usage tracking\"\n",
    "        }),\n",
    "        project_template.substitute({\n",
    "            \"name\": \"AI-Powered Invoice Data Extraction System\",\n",
    "            \"description\": \"Automated data processing pipeline using OpenAI GPT-4o Vision API to extract structured information from invoice images. Integrated multi-source data (SQLite, CSV, images) into unified dataset. Achieved 100% automation of manual invoice processing using LLM with Pydantic validation.\",\n",
    "            \"skills\": comma([\"OpenAI GPT-4o Vision\", \"Pydantic\", \"pandas\", \"SQLite\", \"ETL\", \"Data Integration\"]),\n",
    "            \"result\": \"100% automation, processed 10 invoices with 16+ line items, integrated 3 data sources, type-safe validation\"\n",
    "        }),\n",
    "        project_template.substitute({\n",
    "            \"name\": \"Titanic Disaster Survival Analysis\",\n",
    "            \"description\": \"Comprehensive exploratory data analysis of 1,310 Titanic passengers examining survival patterns by class, gender, age, and family size. Analyzed correlations between socioeconomic status and survival rates, identified rescue priorities (73% female survival vs 20% male), and explored lifeboat allocation patterns across passenger classes.\",\n",
    "            \"skills\": comma([\"pandas\", \"matplotlib\", \"Statistical Analysis\", \"Missing Data Analysis\", \"Correlation Analysis\"]),\n",
    "            \"result\": \"Identified 73% vs 20% survival disparity, handled 77% missing cabin data, analyzed 27 lifeboats\"\n",
    "        }),\n",
    "        project_template.substitute({\n",
    "            \"name\": \"Iris Species Classification - EDA\",\n",
    "            \"description\": \"Comprehensive exploratory data analysis of the classic Iris flower dataset covering three species (setosa, versicolor, virginica). Performed statistical analysis on 150 samples with 4 morphological features, including correlation analysis, distribution studies, and species differentiation using pandas visualization.\",\n",
    "            \"skills\": comma([\"pandas\", \"NumPy\", \"matplotlib\", \"Descriptive Statistics\", \"Data Visualization\"]),\n",
    "            \"result\": \"Identified petal length as strongest discriminator, 0.75 correlation for setosa, zero missing values\"\n",
    "        }),\n",
    "    ]),\n",
    "    skills_languages=comma([\"Python\", \"SQL\"]),\n",
    "    skills_tools=comma([\n",
    "        \"pandas\", \"scikit-learn\", \"PyCaret\",\n",
    "        \"OpenAI API\", \"Streamlit\", \"Plotly\", \"matplotlib\", \"seaborn\",\n",
    "        \"Git\", \"Jupyter Notebook\", \"Docker\"\n",
    "    ]),\n",
    "    skills_databases=comma([\"SQLite\", \"Qdrant\"]),\n",
    "    skills_other=comma([\n",
    "        \"Google Cloud\", \"Digital Ocean\", \"Langfuse\",\n",
    "        \"Prompt Engineering\", \"Vector Databases\", \"REST APIs\"\n",
    "    ]),\n",
    "    portfolio_url=\"https://github.com/ruslanborysenko-lab\",\n",
    "    languages=newline([\n",
    "        language_template.substitute({\"language\": \"English\", \"level\": \"B2\"}),\n",
    "        language_template.substitute({\"language\": \"Polish\", \"level\": \"B2\"}),\n",
    "        language_template.substitute({\"language\": \"Ukrainian\", \"level\": \"Native\"}),\n",
    "    ]),\n",
    "    education=newline([\n",
    "        education_course_template.substitute({\n",
    "            \"course\": \"From Zero to AI\",\n",
    "            \"provider\": \"Gotoit\",\n",
    "            \"date\": \"2025\",\n",
    "        }),\n",
    "        education_school_template.substitute({\n",
    "            \"degree\": \"Bachelor of Engineering - BE, Engineer-constructor\",\n",
    "            \"school\": \"Dniepropetrovsk State University, Ukraine, Faculty of physics and technology\",\n",
    "            \"years\": \"1993-1998\",\n",
    "        }),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "Markdown(cv_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cv_ruslan_borisenco_EN.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(cv_md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "od_zera_do_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
